{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46018953",
   "metadata": {},
   "source": [
    "# PayNet Assessment \n",
    "# Data Cleaning & Visualization using PySpark\n",
    "\n",
    "#### Prepared by: Ainur Afifah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f71526",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Initialize session \n",
    "2. Read JSON into dataframe\n",
    "3. Convert JSON into a tabular format (Flatten the JSON)\n",
    "4. Separate person_name into first name & last name\n",
    "5. Convert timestamp\n",
    "6. Other normalization \n",
    "7. Do charts and visualization (based on the dataset and additional datasets, but this is optional for me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ea4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.11/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6fc644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full schema:\n",
      "root\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- amt: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- cc_bic: string (nullable = true)\n",
      " |-- cc_num: string (nullable = true)\n",
      " |-- is_fraud: string (nullable = true)\n",
      " |-- merch_eff_time: string (nullable = true)\n",
      " |-- merch_last_update_time: string (nullable = true)\n",
      " |-- merch_lat: string (nullable = true)\n",
      " |-- merch_long: string (nullable = true)\n",
      " |-- merch_zipcode: string (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- personal_detail: string (nullable = true)\n",
      " |-- trans_date_trans_time: string (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      "\n",
      "Flattened schema:\n",
      "root\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- trans_date_trans_time_utc8: timestamp (nullable = true)\n",
      " |-- cc_num: string (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- fraud_flag: string (nullable = true)\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: string (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- city_pop: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- birth_month: integer (nullable = true)\n",
      " |-- birth_day: integer (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- merch_lat: string (nullable = true)\n",
      " |-- merch_long: string (nullable = true)\n",
      " |-- is_fraud: string (nullable = true)\n",
      " |-- merch_zipcode: string (nullable = true)\n",
      " |-- merch_eff_time_utc8: string (nullable = true)\n",
      " |-- merch_last_update_time_utc8: string (nullable = true)\n",
      " |-- cc_bic: string (nullable = true)\n",
      " |-- bank_code: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- location_code: string (nullable = true)\n",
      " |-- branch_code: string (nullable = true)\n",
      "\n",
      "\n",
      "Sample flattened data:\n",
      "+----------+--------------------------+----------------+--------------------------+----------+--------------------+--------+----+--------+-----+------+--------------+--------------+-----+-----+-------+--------+--------+-------------------------+----------+-----------+---------+--------------------------------+---------+----------+--------+-------------+-------------------+---------------------------+-----------+---------+------------+-------------+-----------+\n",
      "|Unnamed: 0|trans_date_trans_time_utc8|cc_num          |merchant                  |fraud_flag|merchant_name       |category|amt |first   |last |gender|street        |city          |state|zip  |lat    |long    |city_pop|job                      |birth_year|birth_month|birth_day|trans_num                       |merch_lat|merch_long|is_fraud|merch_zipcode|merch_eff_time_utc8|merch_last_update_time_utc8|cc_bic     |bank_code|country_code|location_code|branch_code|\n",
      "+----------+--------------------------+----------------+--------------------------+----------+--------------------+--------+----+--------+-----+------+--------------+--------------+-----+-----+-------+--------+--------+-------------------------+----------+-----------+---------+--------------------------------+---------+----------+--------+-------------+-------------------+---------------------------+-----------+---------+------------+-------------+-----------+\n",
      "|0         |2019-01-01 00:00:18       |2703186189652095|fraud_Rippin, Kub and Mann|fraud_    |Rippin, Kub and Mann|misc_net|4.97|Jennifer|Banks|F     |561 Perry Cove|Moravian Falls|NC   |28654|36.0788|-81.1781|3495    |Psychologist, counselling|1988      |3          |9        |0b242abb623afc578575680df30655b9|36.011293|-82.048315|0       |28705        |2012-01-01 08:00:18|2012-01-01 08:00:18        |CITIUS33CHI|CITI     |US          |33           |CHI        |\n",
      "+----------+--------------------------+----------------+--------------------------+----------+--------------------+--------+----+--------+-----+------+--------------+--------------+-----+-----+-------+--------+--------+-------------------------+----------+-----------+---------+--------------------------------+---------+----------+--------+-------------+-------------------+---------------------------+-----------+---------+------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, split, concat, lit, substring, regexp_extract\n",
    "from pyspark.sql.functions import date_format, from_unixtime, to_timestamp, from_utc_timestamp\n",
    "from pyspark.sql.functions import regexp_replace, when, array_contains, size, get_json_object\n",
    "from pyspark.sql.functions import to_date, year, month, dayofmonth\n",
    "from pyspark.sql.types import StringType, StructType, StructField\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"cc-sample-data\").getOrCreate()\n",
    "\n",
    "json_file_path = \"/Users/ainurafifah/Desktop/PROJECTS/portfolio/PayNet/cc_sample_transaction.json\"\n",
    "\n",
    "\n",
    "try:\n",
    "    df = spark.read.option(\"multiline\", \"true\").json(json_file_path)\n",
    "    \n",
    "    print(\"Full schema:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Convert timestamp to UTC+8\n",
    "    # Set timezone configuration\n",
    "    spark.conf.set(\"spark.sql.session.timeZone\", \"UTC+8\")\n",
    "    \n",
    "    df = df.withColumn(\n",
    "    \"trans_date_trans_time_utc8\",\n",
    "    to_timestamp(col(\"trans_date_trans_time\"))\n",
    "            )\n",
    "    \n",
    "    df = df.withColumn(\n",
    "    \"merch_eff_time_utc8\",from_unixtime(col(\"merch_eff_time\") / 1000000))\n",
    "\n",
    "    df = df.withColumn(\n",
    "    \"merch_last_update_time_utc8\",\n",
    "    from_unixtime(col(\"merch_last_update_time\") / 1000))\n",
    "    \n",
    "    df = df.withColumn(\"bank_code\", substring(col(\"cc_bic\"), 1, 4))\n",
    "    df = df.withColumn(\"country_code\", substring(col(\"cc_bic\"), 5, 2))\n",
    "    df = df.withColumn(\"location_code\", substring(col(\"cc_bic\"), 7, 2))\n",
    "    df = df.withColumn(\"branch_code\", substring(col(\"cc_bic\"), 9, 3))\n",
    "\n",
    "    df = df.withColumn(\"fraud_flag\",\n",
    "       regexp_extract(col(\"merchant\"), \"^fraud_\", 0))\n",
    "    df = df.withColumn(\"merchant_name\",\n",
    "       regexp_extract(col(\"merchant\"), \"[^_]+$\", 0))\n",
    "\n",
    "        \n",
    "    \n",
    "    # Flattening the JSON\n",
    "    # Define schema for nested structures\n",
    "    address_schema = StructType([\n",
    "                        StructField(\"street\", StringType()),\n",
    "                        StructField(\"city\", StringType()),\n",
    "                        StructField(\"state\", StringType()),\n",
    "                        StructField(\"zip\", StringType())\n",
    "                        ])\n",
    "\n",
    "    personal_detail_schema = StructType([\n",
    "                        StructField(\"person_name\", StringType()),\n",
    "                        StructField(\"gender\", StringType()),\n",
    "                        StructField(\"address\", StringType()),\n",
    "                        StructField(\"lat\", StringType()),\n",
    "                        StructField(\"long\", StringType()),\n",
    "                        StructField(\"city_pop\", StringType()),\n",
    "                        StructField(\"job\", StringType()),   \n",
    "                        StructField(\"dob\", StringType())\n",
    "                        ])\n",
    "\n",
    "    # Parse nested JSON strings\n",
    "    df_parsed = df.withColumn(\"personal_detail_parsed\", \n",
    "                             from_json(\"personal_detail\", personal_detail_schema))\n",
    "    \n",
    "    df_final = df_parsed.withColumn(\"address_parsed\",\n",
    "            from_json(\n",
    "                regexp_replace(col(\"personal_detail_parsed.address\"), r'\\\\\"', '\"'),\n",
    "                address_schema))\n",
    "\n",
    "    # Handling person_name column split\n",
    "    DELIMITERS = [\",\", \"@\", \"/\", \"!\", \"\\\\\\\\\"]\n",
    "    delimiter_pattern = \"|\".join([re.escape(d) for d in DELIMITERS])\n",
    "    \n",
    "    df_final = df_final.withColumn(\n",
    "    \"normalized_name\",\n",
    "        regexp_replace(col(\"personal_detail_parsed.person_name\"), delimiter_pattern, \"|\")\n",
    "    ).withColumn(\n",
    "        \"name_parts\",\n",
    "        split(col(\"normalized_name\"), \"\\\\|\")\n",
    "    )\n",
    "    \n",
    "    spark.conf.set(\"spark.sql.debug.maxToStringFields\", \"1000\")\n",
    "\n",
    "    # Flatten all nested structures\n",
    "    flattened_df = df_final.select(\n",
    "        \"Unnamed: 0\",\n",
    "        \"trans_date_trans_time_utc8\",\n",
    "        \"cc_num\",\n",
    "        \"merchant\",\n",
    "        \"fraud_flag\",\n",
    "        \"merchant_name\",\n",
    "        \"category\",\n",
    "        \"amt\",\n",
    "      \n",
    "        when((size(col(\"name_parts\")) > 0) & (col(\"name_parts\")[0] != \"\"), \n",
    "            col(\"name_parts\")[0]\n",
    "        ).otherwise(lit(None)).alias(\"first\"),\n",
    "        \n",
    "        when((size(col(\"name_parts\")) > 1) & (col(\"name_parts\")[1] != \"\"),\n",
    "            col(\"name_parts\")[1]\n",
    "        ).otherwise(lit(None)).alias(\"last\"),\n",
    "        \n",
    "             \n",
    "        col(\"personal_detail_parsed.gender\").alias(\"gender\"),\n",
    "        col(\"address_parsed.street\").alias(\"street\"),\n",
    "        col(\"address_parsed.city\").alias(\"city\"),\n",
    "        col(\"address_parsed.state\").alias(\"state\"),\n",
    "        col(\"address_parsed.zip\").alias(\"zip\"),\n",
    "        col(\"personal_detail_parsed.lat\").alias(\"lat\"),\n",
    "        col(\"personal_detail_parsed.long\").alias(\"long\"),\n",
    "        col(\"personal_detail_parsed.city_pop\").alias(\"city_pop\"),\n",
    "        col(\"personal_detail_parsed.job\").alias(\"job\"),\n",
    "        year(to_date(col(\"personal_detail_parsed.dob\"))).alias(\"birth_year\"),\n",
    "        month(to_date(col(\"personal_detail_parsed.dob\"))).alias(\"birth_month\"),\n",
    "        dayofmonth(to_date(col(\"personal_detail_parsed.dob\"))).alias(\"birth_day\"),\n",
    "        \"trans_num\",\n",
    "        \"merch_lat\",\n",
    "        \"merch_long\",\n",
    "        \"is_fraud\",\n",
    "        \"merch_zipcode\",\n",
    "        \"merch_eff_time_utc8\",\n",
    "        \"merch_last_update_time_utc8\",\n",
    "        \"cc_bic\",\n",
    "        \"bank_code\",\n",
    "        \"country_code\",\n",
    "        \"location_code\",\n",
    "        \"branch_code\"     \n",
    "    ).drop(\"normalized_name\", \"name_parts\")\n",
    "\n",
    "    print(\"Flattened schema:\")\n",
    "    flattened_df.printSchema()\n",
    "    \n",
    "    print(\"\\nSample flattened data:\")\n",
    "    flattened_df.show(10, truncate=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading JSON file: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
