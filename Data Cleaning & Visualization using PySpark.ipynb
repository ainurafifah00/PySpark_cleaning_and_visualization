{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46018953",
   "metadata": {},
   "source": [
    "# PayNet Assessment \n",
    "# Data Cleaning & Visualization using PySpark\n",
    "\n",
    "#### Prepared by: Ainur Afifah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f71526",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Initialize session \n",
    "2. Read JSON into dataframe\n",
    "3. Convert JSON into a tabular format (Flatten the JSON)\n",
    "    1. personal_details\n",
    "    2. address\n",
    "4. Separate person_name into first name & last name\n",
    "5. Convert timestamp into UTC +8\n",
    "6. Other normalizations:\n",
    "    1. dob\n",
    "    2. merchant name & fraud flag\n",
    "    3. cc_bic -> bank_code, country_code, location_code, branch_code\n",
    "    4. amt column is saved in string -> amount_clean to make sure no negative values\n",
    "    5. is_fraud column is saved in string -> so it is converted into boolean\n",
    "7. Do charts and visualization (based on the dataset and additional datasets, but this is optional for me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ea4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.11/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6fc644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full schema:\n",
      "root\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- amt: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- cc_bic: string (nullable = true)\n",
      " |-- cc_num: string (nullable = true)\n",
      " |-- is_fraud: string (nullable = true)\n",
      " |-- merch_eff_time: string (nullable = true)\n",
      " |-- merch_last_update_time: string (nullable = true)\n",
      " |-- merch_lat: string (nullable = true)\n",
      " |-- merch_long: string (nullable = true)\n",
      " |-- merch_zipcode: string (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- personal_detail: string (nullable = true)\n",
      " |-- trans_date_trans_time: string (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      "\n",
      "Flattened schema:\n",
      "root\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- trans_date_trans_time_utc8: timestamp (nullable = true)\n",
      " |-- cc_num: string (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- fraud_flag: string (nullable = true)\n",
      " |-- derived_fraud_flag: boolean (nullable = false)\n",
      " |-- is_fraud_bool: boolean (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amount_clean: decimal(10,2) (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- city_pop: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- birth_month: integer (nullable = true)\n",
      " |-- birth_day: integer (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- merch_lat: string (nullable = true)\n",
      " |-- merch_long: string (nullable = true)\n",
      " |-- merch_zipcode: string (nullable = true)\n",
      " |-- merch_eff_time_utc8: string (nullable = true)\n",
      " |-- merch_last_update_time_utc8: string (nullable = true)\n",
      " |-- cc_bic: string (nullable = true)\n",
      " |-- bank_code: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- location_code: string (nullable = true)\n",
      " |-- branch_code: string (nullable = true)\n",
      "\n",
      "\n",
      "Sample flattened data:\n",
      "-RECORD 0-------------------------------------------------------\n",
      " Unnamed: 0                  | 0                                \n",
      " trans_date_trans_time_utc8  | 2019-01-01 00:00:18              \n",
      " cc_num                      | 2703186189652095                 \n",
      " merchant                    | fraud_Rippin, Kub and Mann       \n",
      " merchant_name               | Rippin, Kub and Mann             \n",
      " fraud_flag                  | fraud_                           \n",
      " derived_fraud_flag          | true                             \n",
      " is_fraud_bool               | false                            \n",
      " category                    | misc_net                         \n",
      " amount_clean                | 4.97                             \n",
      " first                       | Jennifer                         \n",
      " last                        | Banks                            \n",
      " gender                      | F                                \n",
      " street                      | 561 Perry Cove                   \n",
      " city                        | Moravian Falls                   \n",
      " state                       | NC                               \n",
      " zip                         | 28654                            \n",
      " lat                         | 36.0788                          \n",
      " long                        | -81.1781                         \n",
      " city_pop                    | 3495                             \n",
      " job                         | Psychologist, counselling        \n",
      " birth_year                  | 1988                             \n",
      " birth_month                 | 3                                \n",
      " birth_day                   | 9                                \n",
      " trans_num                   | 0b242abb623afc578575680df30655b9 \n",
      " merch_lat                   | 36.011293                        \n",
      " merch_long                  | -82.048315                       \n",
      " merch_zipcode               | 28705                            \n",
      " merch_eff_time_utc8         | 2012-01-01 08:00:18              \n",
      " merch_last_update_time_utc8 | 2012-01-01 08:00:18              \n",
      " cc_bic                      | CITIUS33CHI                      \n",
      " bank_code                   | CITI                             \n",
      " country_code                | US                               \n",
      " location_code               | 33                               \n",
      " branch_code                 | CHI                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, split, concat, lit, substring, regexp_extract, abs\n",
    "from pyspark.sql.functions import date_format, from_unixtime, to_timestamp, from_utc_timestamp\n",
    "from pyspark.sql.functions import regexp_replace, when, array_contains, size, get_json_object\n",
    "from pyspark.sql.functions import to_date, year, month, dayofmonth\n",
    "from pyspark.sql.types import StringType, StructType, StructField\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"cc-sample-data\").getOrCreate()\n",
    "\n",
    "json_file_path = \"/Users/ainurafifah/Desktop/PROJECTS/portfolio/PayNet/cc_sample_transaction.json\"\n",
    "\n",
    "\n",
    "try:\n",
    "    df = spark.read.option(\"multiline\", \"true\").json(json_file_path)\n",
    "    \n",
    "    print(\"Full schema:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Convert timestamp to UTC+8\n",
    "    # Set timezone configuration\n",
    "    spark.conf.set(\"spark.sql.session.timeZone\", \"UTC+8\")\n",
    "    \n",
    "    df = df.withColumn(\n",
    "    \"trans_date_trans_time_utc8\",\n",
    "    to_timestamp(col(\"trans_date_trans_time\"))\n",
    "            )\n",
    "    \n",
    "    df = df.withColumn(\n",
    "    \"merch_eff_time_utc8\",from_unixtime(col(\"merch_eff_time\") / 1000000))\n",
    "\n",
    "    df = df.withColumn(\n",
    "    \"merch_last_update_time_utc8\",\n",
    "    from_unixtime(col(\"merch_last_update_time\") / 1000))\n",
    "    \n",
    "    # Split cc_bic column into 4 separate columns\n",
    "    df = df.withColumn(\"bank_code\", substring(col(\"cc_bic\"), 1, 4))\n",
    "    df = df.withColumn(\"country_code\", substring(col(\"cc_bic\"), 5, 2))\n",
    "    df = df.withColumn(\"location_code\", substring(col(\"cc_bic\"), 7, 2))\n",
    "    df = df.withColumn(\"branch_code\", substring(col(\"cc_bic\"), 9, 3))\n",
    "    \n",
    "    # Split merchant column into name and fraud flag\n",
    "    df = df.withColumn(\"fraud_flag\",\n",
    "       regexp_extract(col(\"merchant\"), \"^fraud_\", 0))\n",
    "    df = df.withColumn(\"merchant_name\",\n",
    "       regexp_extract(col(\"merchant\"), \"[^_]+$\", 0))\n",
    "    \n",
    "    df = df.withColumn(\"derived_fraud_flag\",\n",
    "    when(col(\"merchant\").startswith(\"fraud_\"), True).otherwise(False))\n",
    "                       \n",
    "    df = df.withColumn(\"is_fraud_bool\",\n",
    "       col(\"is_fraud\").cast(\"boolean\"))\n",
    "\n",
    "    df = df.withColumn(\"amount_clean\",\n",
    "       abs(col(\"amt\").cast(\"decimal(10,2)\"))).filter(col(\"amount_clean\") < 100000)\n",
    "    \n",
    "    \n",
    "    # Flattening the JSON\n",
    "    # Define schema for nested structures\n",
    "    address_schema = StructType([\n",
    "                        StructField(\"street\", StringType()),\n",
    "                        StructField(\"city\", StringType()),\n",
    "                        StructField(\"state\", StringType()),\n",
    "                        StructField(\"zip\", StringType())\n",
    "                        ])\n",
    "\n",
    "    personal_detail_schema = StructType([\n",
    "                        StructField(\"person_name\", StringType()),\n",
    "                        StructField(\"gender\", StringType()),\n",
    "                        StructField(\"address\", StringType()),\n",
    "                        StructField(\"lat\", StringType()),\n",
    "                        StructField(\"long\", StringType()),\n",
    "                        StructField(\"city_pop\", StringType()),\n",
    "                        StructField(\"job\", StringType()),   \n",
    "                        StructField(\"dob\", StringType())\n",
    "                        ])\n",
    "\n",
    "    # Parse nested JSON strings\n",
    "    df_parsed = df.withColumn(\"personal_detail_parsed\", \n",
    "                             from_json(\"personal_detail\", personal_detail_schema))\n",
    "    \n",
    "    df_final = df_parsed.withColumn(\"address_parsed\",\n",
    "            from_json(\n",
    "                regexp_replace(col(\"personal_detail_parsed.address\"), r'\\\\\"', '\"'),\n",
    "                address_schema))\n",
    "\n",
    "    # Handling person_name column split\n",
    "    DELIMITERS = [\",\", \"@\", \"/\", \"!\", \"\\\\\\\\\"]\n",
    "    delimiter_pattern = \"|\".join([re.escape(d) for d in DELIMITERS])\n",
    "    \n",
    "    df_final = df_final.withColumn(\n",
    "    \"normalized_name\",\n",
    "        regexp_replace(col(\"personal_detail_parsed.person_name\"), delimiter_pattern, \"|\")\n",
    "    ).withColumn(\n",
    "        \"name_parts\",\n",
    "        split(col(\"normalized_name\"), \"\\\\|\")\n",
    "    )\n",
    "    \n",
    "    spark.conf.set(\"spark.sql.debug.maxToStringFields\", \"1000\")\n",
    "\n",
    "    # Flatten all nested structures\n",
    "    flattened_df = df_final.select(\n",
    "        \"Unnamed: 0\",\n",
    "        \"trans_date_trans_time_utc8\",\n",
    "        \"cc_num\",\n",
    "        \"merchant\",\n",
    "        \"merchant_name\",\n",
    "        \"fraud_flag\",\n",
    "        \"derived_fraud_flag\",\n",
    "        \"is_fraud_bool\",\n",
    "        \"category\",\n",
    "        \"amount_clean\",\n",
    "      \n",
    "        when((size(col(\"name_parts\")) > 0) & (col(\"name_parts\")[0] != \"\"), \n",
    "            col(\"name_parts\")[0]\n",
    "        ).otherwise(lit(None)).alias(\"first\"),\n",
    "        \n",
    "        when((size(col(\"name_parts\")) > 1) & (col(\"name_parts\")[1] != \"\"),\n",
    "            col(\"name_parts\")[1]\n",
    "        ).otherwise(lit(None)).alias(\"last\"),\n",
    "        \n",
    "             \n",
    "        col(\"personal_detail_parsed.gender\").alias(\"gender\"),\n",
    "        col(\"address_parsed.street\").alias(\"street\"),\n",
    "        col(\"address_parsed.city\").alias(\"city\"),\n",
    "        col(\"address_parsed.state\").alias(\"state\"),\n",
    "        col(\"address_parsed.zip\").alias(\"zip\"),\n",
    "        col(\"personal_detail_parsed.lat\").alias(\"lat\"),\n",
    "        col(\"personal_detail_parsed.long\").alias(\"long\"),\n",
    "        col(\"personal_detail_parsed.city_pop\").alias(\"city_pop\"),\n",
    "        col(\"personal_detail_parsed.job\").alias(\"job\"),\n",
    "        year(to_date(col(\"personal_detail_parsed.dob\"))).alias(\"birth_year\"),\n",
    "        month(to_date(col(\"personal_detail_parsed.dob\"))).alias(\"birth_month\"),\n",
    "        dayofmonth(to_date(col(\"personal_detail_parsed.dob\"))).alias(\"birth_day\"),\n",
    "        \"trans_num\",\n",
    "        \"merch_lat\",\n",
    "        \"merch_long\",\n",
    "        \"merch_zipcode\",\n",
    "        \"merch_eff_time_utc8\",\n",
    "        \"merch_last_update_time_utc8\",\n",
    "        \"cc_bic\",\n",
    "        \"bank_code\",\n",
    "        \"country_code\",\n",
    "        \"location_code\",\n",
    "        \"branch_code\"     \n",
    "    ).drop(\"normalized_name\", \"name_parts\")\n",
    "\n",
    "    print(\"Flattened schema:\")\n",
    "    flattened_df.printSchema()\n",
    "    \n",
    "    print(\"\\nSample flattened data:\")\n",
    "    flattened_df.show(truncate=False, vertical=True)\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b620ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, when\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def handle_nulls(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Handle null/missing values with column-specific strategies\"\"\"\n",
    "    # Define treatment for each column type\n",
    "    return df.na.fill({\n",
    "        # String columns\n",
    "        \"merchant_name\": \"unknown_merchant\",\n",
    "        \"first\": \"unknown_first\",\n",
    "        \"last\": \"unknown_last\",\n",
    "        \"gender\": \"U\",  # 'U' for unknown\n",
    "        \"street\": \"unknown_street\",\n",
    "        \"city\": \"unknown_city\",\n",
    "        \"state\": \"unknown_state\",\n",
    "        \"job\": \"unknown_job\",\n",
    "        \n",
    "        # Numeric columns\n",
    "        \"amount_clean\": 0.0,\n",
    "        \"lat\": 0.0,\n",
    "        \"long\": 0.0,\n",
    "        \"city_pop\": 0,\n",
    "        \"birth_year\": 1900,  # Default for unknown birth year\n",
    "        \"birth_month\": 1,\n",
    "        \"birth_day\": 1,\n",
    "        \n",
    "        # Boolean columns\n",
    "        \"fraud_flag\": False,\n",
    "        \"derived_fraud_flag\": False,\n",
    "        \"is_fraud_bool\": False,\n",
    "        \n",
    "        # Code columns\n",
    "        \"zip\": \"00000\",\n",
    "        \"merch_zipcode\": \"00000\",\n",
    "        \"bank_code\": \"XXXX\",\n",
    "        \"country_code\": \"XX\",\n",
    "        \"location_code\": \"XX\",\n",
    "        \"branch_code\": \"XXX\"\n",
    "    })\n",
    "\n",
    "\n",
    "def handle_duplicates(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Identify and remove duplicates with key columns\"\"\"\n",
    "    # Define uniqueness criteria\n",
    "    key_columns = [\"trans_num\", \"cc_num\", \"trans_date_trans_time_utc8\"]\n",
    "    \n",
    "    # Mark duplicates\n",
    "    from pyspark.sql.window import Window\n",
    "    window = Window.partitionBy(key_columns).orderBy(\"merch_eff_time_utc8\")\n",
    "    \n",
    "    df = df.withColumn(\"is_duplicate\", \n",
    "                      (count(\"*\").over(window) > 1))\n",
    "    \n",
    "    # Optional: Show duplicates before removal\n",
    "    df.filter(col(\"is_duplicate\")).show()\n",
    "    \n",
    "    # Keep only first occurrence\n",
    "    return df.dropDuplicates(key_columns).drop(\"is_duplicate\")\n",
    "\n",
    "def validate_data(df: DataFrame) -> None:\n",
    "    \"\"\"Run comprehensive data quality checks\"\"\"\n",
    "    # Null check\n",
    "    null_counts = df.select([\n",
    "        count(when(col(c).isNull() | (col(c) == \"\"), c)).alias(c) \n",
    "        for c in df.columns\n",
    "    ])\n",
    "    print(\"Null/empty value counts:\")\n",
    "    null_counts.show(vertical=True)\n",
    "    \n",
    "    # Duplicate check\n",
    "    duplicate_count = df.count() - df.dropDuplicates([\"trans_num\"]).count()\n",
    "    print(f\"\\nDuplicate transactions: {duplicate_count}\")\n",
    "    \n",
    "    # Value range checks\n",
    "    df.select(\n",
    "        count(when(col(\"amount_clean\") < 0, True)).alias(\"negative_amounts\"),\n",
    "        count(when(col(\"birth_year\") < 1900, True)).alias(\"invalid_birth_years\"),\n",
    "        count(when(~col(\"country_code\").rlike(\"^[A-Z]{2}$\"), True)).alias(\"invalid_country_codes\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4967206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------+------+--------+-------------+----------+------------------+-------------+--------+------------+-----+----+------+------+----+-----+---+---+----+--------+---+----------+-----------+---------+---------+---------+----------+-------------+-------------------+---------------------------+------+---------+------------+-------------+-----------+------------+\n",
      "|Unnamed: 0|trans_date_trans_time_utc8|cc_num|merchant|merchant_name|fraud_flag|derived_fraud_flag|is_fraud_bool|category|amount_clean|first|last|gender|street|city|state|zip|lat|long|city_pop|job|birth_year|birth_month|birth_day|trans_num|merch_lat|merch_long|merch_zipcode|merch_eff_time_utc8|merch_last_update_time_utc8|cc_bic|bank_code|country_code|location_code|branch_code|is_duplicate|\n",
      "+----------+--------------------------+------+--------+-------------+----------+------------------+-------------+--------+------------+-----+----+------+------+----+-----+---+---+----+--------+---+----------+-----------+---------+---------+---------+----------+-------------+-------------------+---------------------------+------+---------+------------+-------------+-----------+------------+\n",
      "+----------+--------------------------+------+--------+-------------+----------+------------------+-------------+--------+------------+-----+----+------+------+----+-----+---+---+----+--------+---+----------+-----------+---------+---------+---------+----------+-------------+-------------------+---------------------------+------+---------+------------+-------------+-----------+------------+\n",
      "\n",
      "Null/empty value counts:\n",
      "-RECORD 0--------------------------\n",
      " Unnamed: 0                  | 0   \n",
      " trans_date_trans_time_utc8  | 0   \n",
      " cc_num                      | 0   \n",
      " merchant                    | 0   \n",
      " merchant_name               | 0   \n",
      " fraud_flag                  | 0   \n",
      " derived_fraud_flag          | 0   \n",
      " is_fraud_bool               | 0   \n",
      " category                    | 0   \n",
      " amount_clean                | 0   \n",
      " first                       | 0   \n",
      " last                        | 0   \n",
      " gender                      | 0   \n",
      " street                      | 0   \n",
      " city                        | 0   \n",
      " state                       | 0   \n",
      " zip                         | 0   \n",
      " lat                         | 0   \n",
      " long                        | 0   \n",
      " city_pop                    | 0   \n",
      " job                         | 0   \n",
      " birth_year                  | 0   \n",
      " birth_month                 | 0   \n",
      " birth_day                   | 0   \n",
      " trans_num                   | 0   \n",
      " merch_lat                   | 0   \n",
      " merch_long                  | 0   \n",
      " merch_zipcode               | 0   \n",
      " merch_eff_time_utc8         | 0   \n",
      " merch_last_update_time_utc8 | 0   \n",
      " cc_bic                      | 0   \n",
      " bank_code                   | 0   \n",
      " country_code                | 0   \n",
      " location_code               | 0   \n",
      " branch_code                 | 0   \n",
      "\n",
      "\n",
      "Duplicate transactions: 0\n",
      "+----------------+-------------------+---------------------+\n",
      "|negative_amounts|invalid_birth_years|invalid_country_codes|\n",
      "+----------------+-------------------+---------------------+\n",
      "|               0|                  0|                    0|\n",
      "+----------------+-------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply all cleaning steps\n",
    "cleaned_df = (flattened_df.transform(handle_nulls).transform(handle_duplicates))\n",
    "\n",
    "# Validate results\n",
    "validate_data(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0d749c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " Unnamed: 0                  | 0                    \n",
      " trans_date_trans_time_utc8  | 2019-01-01 00:00:18  \n",
      " cc_num                      | 2703186189652095     \n",
      " merchant                    | fraud_Rippin, Kub... \n",
      " merchant_name               | Rippin, Kub and Mann \n",
      " fraud_flag                  | fraud_               \n",
      " derived_fraud_flag          | true                 \n",
      " is_fraud_bool               | false                \n",
      " category                    | misc_net             \n",
      " amount_clean                | 4.97                 \n",
      " first                       | Jennifer             \n",
      " last                        | Banks                \n",
      " gender                      | F                    \n",
      " street                      | 561 Perry Cove       \n",
      " city                        | Moravian Falls       \n",
      " state                       | NC                   \n",
      " zip                         | 28654                \n",
      " lat                         | 36.0788              \n",
      " long                        | -81.1781             \n",
      " city_pop                    | 3495                 \n",
      " job                         | Psychologist, cou... \n",
      " birth_year                  | 1988                 \n",
      " birth_month                 | 3                    \n",
      " birth_day                   | 9                    \n",
      " trans_num                   | 0b242abb623afc578... \n",
      " merch_lat                   | 36.011293            \n",
      " merch_long                  | -82.048315           \n",
      " merch_zipcode               | 28705                \n",
      " merch_eff_time_utc8         | 2012-01-01 08:00:18  \n",
      " merch_last_update_time_utc8 | 2012-01-01 08:00:18  \n",
      " cc_bic                      | CITIUS33CHI          \n",
      " bank_code                   | CITI                 \n",
      " country_code                | US                   \n",
      " location_code               | 33                   \n",
      " branch_code                 | CHI                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.show(5, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1133bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
